{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA-A8X97da3A"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8_FLK8ff75m",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "2d091551-d80c-4414-c819-52f73d8d6985"
      },
      "source": [
        "\"\"\"\n",
        "In this task I opt to create my own dataset using ag_news csv files rather than\n",
        "using torchtext inbuilt dataset. This is with the intention to have more\n",
        "flexibility with respect to changing the data format as required for our model.\n",
        "\n",
        "Download the ag_news dataset tar file from the link below:\n",
        "https://drive.google.com/drive/u/0/folders/0Bz8a_Dbh9Qhbfll6bVpmNUtUcFdjYmF2SEpmZUZUcVNiMUw1TWN6RDV3a0JHT3kxLVhVR2M\n",
        "\n",
        "Upload the downloaded tar file after running the below code snippet.\n",
        "\"\"\"\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-18ecc520-5bf7-48ed-80d3-2209e876cf37\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-18ecc520-5bf7-48ed-80d3-2209e876cf37\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving ag_news_csv.tar.gz to ag_news_csv.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejIf5e677q_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf7537a4-ae42-4d5b-d7d0-6256698b4e8a"
      },
      "source": [
        "# Extracting the dataset folder to obtain csv files\n",
        "!tar xvzf  ag_news_csv.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ag_news_csv/\n",
            "ag_news_csv/train.csv\n",
            "ag_news_csv/test.csv\n",
            "ag_news_csv/classes.txt\n",
            "ag_news_csv/readme.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQddcpK4m-uT"
      },
      "source": [
        "# Obtaining a dataframe from the train.csv file\n",
        "df = pd.read_csv('ag_news_csv/train.csv', header=None, index_col=None)\n",
        "\n",
        "# Assigning names to the columns\n",
        "df.columns = ['label', 'title', 'text']\n",
        "\n",
        "# By inspection it is found that class labels are in the range {1,2,3,4}\n",
        "# In order to maintain consistency with inbuilt dataset,\n",
        "# the range is changed to {0,1,2,3}\n",
        "df['label'] = df['label']-1\n",
        "\n",
        "# The data with named colums and changed label range is stored in csv\n",
        "df[['label', 'text']].to_csv('ag_news_csv/train_labeled.csv', index=None)\n",
        "\n",
        "# Similar steps are carried out for test.csv file\n",
        "df = pd.read_csv('ag_news_csv/test.csv', header=None, index_col=None)\n",
        "df.columns = ['label', 'title', 'text']\n",
        "df['label'] = df['label']-1\n",
        "df[['label', 'text']].to_csv('ag_news_csv/test_labeled.csv', index=None)\n",
        "\n",
        "# Delete the dataframe\n",
        "del df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT9HeL1M1_ZO"
      },
      "source": [
        "# A method that creates tabular dataset using the csv file in the given path\n",
        "# according to the fields specified\n",
        "def get_dataset_from_csv(path_to_csv, fields):\n",
        "    dataset = data.TabularDataset(path = path_to_csv, format='csv',\n",
        "    skip_header=True, fields=fields)\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjy20B2lldgQ"
      },
      "source": [
        "\"\"\" Using the Field and LabelField options of torchtext to define the\n",
        "preprocessing to be performed on the data before converting to tensor.\n",
        "sequential: is set to true since our data is sequential\n",
        "tokenize: spacy is used because it performs better than the default str.split\n",
        "include_length: true because we require pack_padded_sequence \"\"\"\n",
        "TEXT = data.Field(sequential=True,\n",
        "                  tokenize='spacy',\n",
        "                  include_lengths=True)\n",
        "\n",
        "LABEL = data.LabelField(dtype=torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLLH4xnTlkPM"
      },
      "source": [
        "# List of fields required in the dataset\n",
        "fields = [('label', LABEL), ('text', TEXT)]\n",
        "\n",
        "# Getting train and test dataset from respective csv files\n",
        "train_dataset = get_dataset_from_csv(\"ag_news_csv/train_labeled.csv\", fields)\n",
        "test_dataset = get_dataset_from_csv(\"ag_news_csv/test_labeled.csv\", fields)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVmurBLllnQ8"
      },
      "source": [
        "# Since there is no seperate validation dataset we split the train dataset\n",
        "# split ratio is 0.95 (Same as in task 1)\n",
        "train_data, valid_data = train_dataset.split(split_ratio=[0.95, 0.05],\n",
        "    random_state=random.seed(100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ1gSyHPyvnt"
      },
      "source": [
        "torch.backends.cudnn.deterministic = True\n",
        "torch.manual_seed(100)\n",
        "\n",
        "VOCABULARY_SIZE = 5000\n",
        "BATCH_SIZE = 128\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwCkrtPalzIl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32403fea-27a2-48cd-961e-60b90295b28d"
      },
      "source": [
        "\"\"\"\n",
        "I use the pre-trained embeddings since symantically closed words are close in\n",
        "this embedding. I have taken the embedding of dimension 100 obtained by training\n",
        "on 6 billion tokens.\n",
        "\"\"\"\n",
        "TEXT.build_vocab(train_data, max_size=VOCABULARY_SIZE, vectors='glove.6B.100d',\n",
        "                 unk_init=torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:26, 2.23MB/s]                           \n",
            "100%|█████████▉| 399379/400000 [00:16<00:00, 24737.75it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl-8KHp3qxG3"
      },
      "source": [
        "\"\"\"\n",
        "I obtain the iterators for train, validation and test dataset.\n",
        "BucketIterator returns an a batch containing samples of similar size.\n",
        "Since I have packed_padded_sequence, it is necessary to sort within batch\n",
        "according to length. Hence, sort_within_batch is set true and sort_key is used\n",
        "for defining sorting criterion as length.\n",
        "\"\"\"\n",
        "train_loader, valid_loader, test_loader = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_dataset), batch_size=BATCH_SIZE,\n",
        "    sort_within_batch=True, sort_key=lambda l: len(l.text), device=DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0Ohxc0Uq1Cm"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\"\"\"\n",
        "In the model I have tried to implement a variation of the RNN model.\n",
        "I have used LSTM as it considers wider context. I have used Bidirectional\n",
        "LSTM because it considers future as well as past context.\n",
        "I have used 2 layers of LSTM. I have also used dropout to minimise overfitting.\n",
        "By trial and error I have chosen a dropout probability of 0.5\n",
        "\"\"\"\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        # An embedding layer. Setting the padding_idx as pad_idx is to indicate to\n",
        "        # embedding layer to not process padded tokens. It is left unchanged. Hence\n",
        "        # when LSTM gets padding tokens it does not process them.\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
        "\n",
        "        # Defining a biderection LSTM (bidirectional=True) with 2 layers(num_layers=2)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, dropout=0.5,\n",
        "                           bidirectional=True)\n",
        "\n",
        "        # Hidden states has both forward and backward component. Hence multiplied by 2\n",
        "        # Intermediate linear layer of dimension = 32\n",
        "        self.fc1 = nn.Linear(hidden_dim * 2, 32)\n",
        "\n",
        "        # Final linear layer.\n",
        "        self.fc2 = nn.Linear(32, output_dim)\n",
        "\n",
        "        # Initializes the dropout layer\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, text, text_length):\n",
        "        # Apply droput on the embedding of the text\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        # I want to pass the text length as I am using packed_padded_sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_length)\n",
        "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
        "        # As I have two layers I am concatenating the hidden states before passing\n",
        "        # it to the next linear layer. After concatenating dropout is applied.\n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
        "        hidden = self.fc1(hidden)\n",
        "        hidden = self.fc2(hidden)\n",
        "        return hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA04uh5Uq1cz"
      },
      "source": [
        "# Input dimension is length of the vocabulary\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "# Instantiating the model Classifier\n",
        "model = Classifier(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, PAD_IDX)\n",
        "# Moving the model to device\n",
        "model = model.to(DEVICE)\n",
        "# Instantiating the optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMOsRdNBq1qY"
      },
      "source": [
        "# Method to evaluate the model accuracy\n",
        "def evaluate_result(model, data_loader, device):\n",
        "    # Putting the model in the evaluation mode\n",
        "    model.eval()\n",
        "    valid_predictions = 0\n",
        "    total_data_points = 0\n",
        "    # Performing the below steps excluding from the torch grad\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch_data in enumerate(data_loader):\n",
        "            text, text_lengths = batch_data.text\n",
        "            # Obtaining the probabilities for datapoints in the current batch\n",
        "            probabilities = model(text, text_lengths).squeeze(1)\n",
        "\n",
        "            # Obtaining the indices (labels) of greatest value of probability for all elements in the batch\n",
        "            _, response_labels = torch.max(probabilities, 1)\n",
        "\n",
        "            # Maintaining the count of total data points\n",
        "            total_data_points += batch_data.label.size(0)\n",
        "\n",
        "            # Maintaining the count of total correct predictions\n",
        "            valid_predictions += (response_labels.long() == batch_data.label.long()).sum()\n",
        "\n",
        "        # returns the accuracy. Accuracy = correct_predictions/total_predictions\n",
        "        return valid_predictions.float()/total_data_points * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_E8tNUnrJEm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "19602d7a-3c21-4563-b199-52ad46135930"
      },
      "source": [
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    # putting the model in the train mode\n",
        "    model.train()\n",
        "    for batch_idx, batch_data in enumerate(train_loader):\n",
        "\n",
        "        text, text_lengths = batch_data.text\n",
        "\n",
        "        # Forward propogation\n",
        "        output = model(text, text_lengths).squeeze(1)\n",
        "        # cost is computed using cross_entropy as loss function\n",
        "        cost = F.cross_entropy(output, batch_data.label.long())\n",
        "        # Setting gradients to zero\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Performing back propogation\n",
        "        cost.backward()\n",
        "\n",
        "        # Updating the parameters\n",
        "        optimizer.step()\n",
        "\n",
        "    with torch.set_grad_enabled(False):\n",
        "        print(f'Epoch: '\n",
        "              f'{epoch}'\n",
        "              f'\\ntraining accuracy: '\n",
        "              f'{evaluate_result(model, train_loader, DEVICE):.3f}%'\n",
        "              f'\\nvalidation accuracy: '\n",
        "              f'{evaluate_result(model, valid_loader, DEVICE):.3f}%')\n",
        "\n",
        "print(f'Test accuracy: {evaluate_result(model, test_loader, DEVICE):.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "training accuracy: 94.838%\n",
            "validation accuracy: 91.000%\n",
            "Epoch: 1\n",
            "training accuracy: 95.365%\n",
            "validation accuracy: 91.183%\n",
            "Epoch: 2\n",
            "training accuracy: 95.478%\n",
            "validation accuracy: 91.317%\n",
            "Epoch: 3\n",
            "training accuracy: 95.636%\n",
            "validation accuracy: 90.783%\n",
            "Epoch: 4\n",
            "training accuracy: 95.773%\n",
            "validation accuracy: 91.183%\n",
            "Epoch: 5\n",
            "training accuracy: 96.156%\n",
            "validation accuracy: 91.183%\n",
            "Epoch: 6\n",
            "training accuracy: 96.410%\n",
            "validation accuracy: 91.200%\n",
            "Epoch: 7\n",
            "training accuracy: 96.479%\n",
            "validation accuracy: 90.983%\n",
            "Epoch: 8\n",
            "training accuracy: 96.417%\n",
            "validation accuracy: 91.150%\n",
            "Epoch: 9\n",
            "training accuracy: 96.709%\n",
            "validation accuracy: 91.133%\n",
            "Test accuracy: 91.07%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}